<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Sungmin Woo</title>
  <meta name="Sungmin Woo's Homepage" http-equiv="Content-Type" content="Sungmin Woo's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-154732200-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-154732200-1');
  </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sungmin Woo</name>
              </p>
              <p>
                I am a Ph.D candidate at <a href="https://www.yonsei.ac.kr">Yonsei University</a>, Seoul, Korea.
              </p>
              <p>
                My research mainly focuses on 3D computer vision tasks such as depth estimation, point cloud processing, neural rendering, and motion prediction.
              </p>
              <p>
                Please feel free to contact me if you have any questions or suggestions :)
              </p>
              <!-- <p>
                I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:dogyoonlee@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume/dogyoonlee-resume.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/resume/dogyoonlee-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=ww2vWOcAAAAJ&hl=ko">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/dogyoonlee/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/dogyoonlee.png">
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
<!-- 
<tr onmouseout="dpnerf_stop()" onmouseover="dpnerf_start()"  bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='dpnerf_image'><video  width=100% height=100% muted autoplay loop>
      <source src="images/dpnerf/dpnerf_video.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='images/dpnerf/dpnerf_image.png' width="160">
    </div>
    <script type="text/javascript">
      function dpnerf_start() {
        document.getElementById('dpnerf_image').style.opacity = "1";
      }

      function dpnerf_stop() {
        document.getElementById('dpnerf_image').style.opacity = "0";
      }
      dpnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">
      <papertitle>DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=flyFxPsAAAAJ&hl=ko&oi=ao">Chajin Shin</a>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2023 
    <br>
    <a href="https://dogyoonlee.github.io/dpnerf">Project page</a>
    /
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/DP-NeRF">Code</a>
    /
    <a href="data/bib/dpnerf2023.txt">bib</a>
    <p></p>
    <p>
    We impose the physical constraints on the blurring kernel of neural radiance field to construct clean neural radiance field from blurry images.
    </p>
  </td>
</tr> -->

<tr onmouseout="pcvr_stop()" onmouseover="pcvr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='pcvr_image'>
        <img src='images/pcvr/pcvr_after.png' width="160">
      </div>
      <img src='images/pcvr/pcvr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function pcvr_start() {
        document.getElementById('pcvr_image').style.opacity = "1";
      }

      function pcvr_stop() {
        document.getElementById('pcvr_image').style.opacity = "0";
      }
      pcvr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf"> -->
      <papertitle>ProDepth: Boosting Self-Supervised Multi-Frame Monocular Depth with Probabilistic Fusion</papertitle>
    <!-- </a> -->
    <br>
    <strong>Sungmin Woo*</strong>,
    Wonjoon Lee*,
    Woojin Kim,
    Dogyoon Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>European Conference on Computer Vision (ECCV) </em>, 2024 
    <br>
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/SVL">Code</a>
    /
    <a href="data/bib/svl2024.txt">bib</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel framework called ProDepth, which effectively addresses the mismatch problem caused by dynamic objects using a probabilistic approach.
    </p>
  </td>
</tr>

<tr onmouseout="gsa_stop()" onmouseover="gsa_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='gsa_image'>
        <img src='images/gsa/slot_attention_after.png' width="160">
      </div>
      <img src='images/gsa/slot_attention_before.png' width="160">
    </div>
    <script type="text/javascript">
      function gsa_start() {
        document.getElementById('gsa_image').style.opacity = "1";
      }

      function gsa_stop() {
        document.getElementById('gsa_image').style.opacity = "0";
      }
      gsa_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2303.08314.pdf">
      <papertitle>FIMP: Future Interaction Modeling for Multi-Agent Motion Prediction</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Minjung Kim,
    Donghyeong Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024 
    <br>
    <a href="https://arxiv.org/pdf/2401.16189">Paper</a>
    /
    <a href="https://github.com/Hydragon516/GSANet?tab=readme-ov-file">Code</a>
    /
    <a href="data/bib/gsa_2024.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose Future Interaction modeling for Motion Prediction (FIMP), which captures potential future interactions in an endto-end manner.
    </p>
  </td>
</tr>


<tr onmouseout="mkconv_stop()" onmouseover="mkconv_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='mkconv_image'>
        <img src='images/mkconv/mkconv_after.png' width="160"></div>
      <img src='images/mkconv/mkconv_before.png' width="160">
    </div>
    <script type="text/javascript">
      function mkconv_start() {
        document.getElementById('mkconv_image').style.opacity = "1";
      }

      function mkconv_stop() {
        document.getElementById('mkconv_image').style.opacity = "0";
      }
      mkconv_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4332140">
      <papertitle>MKConv: Multidimensional Feature Representation for Point Cloud Analysis</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Dogyoon Lee,
    Sangwon Hwang,
    Woojin Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>Pattern Recognition (PR)</em>, 2023
    <br>
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4332140">Paper</a>
    <!-- / -->
    <!-- <a href="https://">Code</a> -->
    /
    <a href="data/bib/mkconv2023.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel convolution operation for point cloud processing, introducing a multidimensional feature representation.
    </p>
  </td>
</tr>

		
<tr onmouseout="robustlane_stop()" onmouseover="robustlane_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='robust_lane_image'>
        <img src='images/robust_lane/lane_after.png' width="160"></div>
      <img src='images/robust_lane/lane_before.png' width="160">
    </div>
    <script type="text/javascript">
      function robustlane_start() {
        document.getElementById('robust_lane_image').style.opacity = "1";
      }

      function robustlane_stop() {
        document.getElementById('robust_lane_image').style.opacity = "0";
      }
      robustlane_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2102.07037.pdf">
      <papertitle>Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition</papertitle>
    </a>
    <br>
    Jungho Lee,
    Minhyeok Lee,
    Suhwan Cho,
    <strong>Sungmin Woo</strong>,
    Sungjun Jang,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023
    <br>
    <a href="https://arxiv.org/pdf/2102.07037.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/ESA-official">Code</a>
    /
    <a href="data/bib/robustlane2022.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel Spatio-Temporal Curve Network (STC-Net) for skeleton-based action recognition, which consists of spatial modules with an spatio-temporal curve (STC) module and graph convolution with dilated kernels.
    </p>
  </td>
</tr>

<tr onmouseout="fpr_stop()" onmouseover="fpr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='fpr_image'>
        <img src='images/fpr/fpr_after.png' width="160"></div>
      <img src='images/fpr/fpr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function fpr_start() {
        document.getElementById('fpr_image').style.opacity = "1";
      }

      function fpr_stop() {
        document.getElementById('fpr_image').style.opacity = "0";
      }
      fpr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2005.13153.pdf">
      <papertitle>MSV-RGNN: Multiscale Voxel Graph Neural Network for 3D Object Detection</papertitle>
    </a>
    <br>
    Wonjoon Lee,
    <strong>Sungmin Woo</strong>,
    Donghyeong Kim,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2023
    <br>
    <a href="https://arxiv.org/pdf/2005.13153.pdf">Paper</a>
    /
    <a href="data/bib/fpr2020.txt">bib</a>
    <!-- /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose MSV-RGNN, a two-stage 3D object detector that utilizes multiple sets of graphs across all scales via a multiscale-voxel-graph RoI pooling module.
    </p>
  </td>
</tr>

<tr onmouseout="fpr_stop()" onmouseover="fpr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='fpr_image'>
        <img src='images/fpr/fpr_after.png' width="160"></div>
      <img src='images/fpr/fpr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function fpr_start() {
        document.getElementById('fpr_image').style.opacity = "1";
      }

      function fpr_stop() {
        document.getElementById('fpr_image').style.opacity = "0";
      }
      fpr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2005.13153.pdf">
      <papertitle>Detection-Identification Balancing Margin Loss for One-Stage Multi-Object Tracking</papertitle>
    </a>
    <br>
    Heansung Lee, 
    Suhwan Cho, 
    Sungjun Jang,
    Jungho Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2022
    <br>
    <a href="https://arxiv.org/pdf/2005.13153.pdf">Paper</a>
    /
    <a href="data/bib/fpr2020.txt">bib</a>
    <!-- /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We present a Detection-Identification balancing Margin loss on one-stage MOT for suppressing negative transfer effect to achieve balanced performance of detection and re-ID.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>Regularization Strategy for Point Cloud via Rigidly Mixed Sample</papertitle>
    </a>
    <br>
    Dogyoon Lee,
    Jaeha Lee,
    Junhyeop Lee,
    Hyeongmin Lee,
    Minhyeok Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    /
    <a href="data/bib/rsmix2021.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel data augmentation method called Rigid Subset Mix (RSMix) which generates virtual mixed samples by replacing part of the sample with shape-preserved subsets from another sample.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>Lidar depth completion using color-embedded information via knowledge distillation</papertitle>
    </a>
    <br>
    Sangwon Hwang,
    Junhyeop Lee,
    Woojin Kim,
    <strong>Sungmin Woo</strong>,
    Kyungjae Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    /
    <a href="data/bib/rsmix2021.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We present a depth completion framework consisting of depth and edge CNNs with transferring of knowledge.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>AIBM: Accurate and instant background modeling for moving object detection</papertitle>
    </a>
    <br>
    Woojin Kim,
    Sangwon Hwang,
    Junhyeop Lee,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE Transactions on Intelligent Transportation Systems (T-ITS)</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    /
    <a href="data/bib/rsmix2021.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel background modeling method for moving object detection based on inpainting and enhancing the resolution using a coarse-to-fine strategy.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>Ghost graph convolutional network for skeleton-based action recognition</papertitle>
    </a>
    <br>
    Sungjun Jang,
    Heansung Lee,
    Suhwan Cho,
    <strong>Sungmin Woo</strong>,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia))</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    /
    <a href="data/bib/rsmix2021.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a ghost graph convolution for skeleton-based action recognition.
    </p>
  </td>
</tr>

<tr onmouseout="fpr_stop()" onmouseover="fpr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='fpr_image'>
        <img src='images/fpr/fpr_after.png' width="160"></div>
      <img src='images/fpr/fpr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function fpr_start() {
        document.getElementById('fpr_image').style.opacity = "1";
      }

      function fpr_stop() {
        document.getElementById('fpr_image').style.opacity = "0";
      }
      fpr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2005.13153.pdf">
      <papertitle>False Positive Removal For 3D Vehicle Detection with Penetrated Point Classifier</papertitle>
    </a>
    <br>
    <strong>Sungmin Woo</strong>,
    Sangwon Hwang,
    Woojin Kim,
    Junhyeop Lee,
    Dogyoon Lee,
    Sangyoun Lee
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2020
    <br>
    <a href="https://arxiv.org/pdf/2005.13153.pdf">Paper</a>
    /
    <a href="data/bib/fpr2020.txt">bib</a>
    <!-- /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel post-processing method to remove false positives in 3D vehicle detection utilizing the characteristics of the LiDAR censor itself.
    </p>
  </td>
</tr>

</tbody></table>

				
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Preprint</heading>
        </td>
      </tr>
    </tbody>
  </table>
  

      <!-- <tr>
        <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cvf.jpg">
        </td>
        <td width="75%" valign="center">
          <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
          <br>
          <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
          <br>
          <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
          <br>
          <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
        </td>
      </tr>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cs188.jpg" alt="cs188">
        </td>
        <td width="75%" valign="center">
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
          <br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
          <br>
          <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
        </td>
      </tr>
      

      <tr>
        <td align="center" style="padding:20px;width:25%;vertical-align:middle">
          <heading>Basically <br> Blog Posts</heading>
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
          <br>
          <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
          <br>
          <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
        </td>
      </tr>
        -->	
    </tbody>
  </table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            This website's source code is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron's website</a>.
          </p>
          <p style="text-align:right;font-size:small;">
            Last updated July 2024.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  <!-- </td>
  </tr> -->
<!-- </table> -->
</body>

</html>
